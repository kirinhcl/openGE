"""
æµ‹è¯•è„šæœ¬ï¼šç”¨äºæµ‹è¯• environment.py çš„åŠŸèƒ½
æµ‹è¯•æ•°æ®æ–‡ä»¶ï¼š
- 3_Testing_Soil_Data_2024.csv
- 4_Testing_Weather_Data_2024_seasons_only.csv
- 6_Testing_EC_Data_2024.csv

åŠŸèƒ½ï¼š
1. åŠ è½½ä¸‰ä¸ªæ•°æ®æ–‡ä»¶
2. å¤©æ°”æ–‡ä»¶ä¸åšèšåˆï¼ˆä¿ç•™æ—¶é—´åºåˆ—ï¼‰
3. åˆå¹¶ä¸‰ä¸ªæ•°æ®æº
4. è¾“å‡ºä¸º CSV æ–‡ä»¶
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
from datetime import datetime

# âœ… ã€ä¿®æ”¹ã€‘å¯¼å…¥ EnvironmentLoader ç±»
# æ–¹å¼1ï¼šå¦‚æœ environment.py åœ¨ openge/data/loaders/ ç›®å½•
sys.path.insert(0, str(Path(__file__).parent / 'openge'))
from openge.data import EnvironmentLoader


def test_environment_loader():
    """æµ‹è¯• EnvironmentLoader ç±»"""
    print("\n" + "=" * 60)
    print("TEST 0: EnvironmentLoader ç±»åˆå§‹åŒ–")
    print("=" * 60)
    
    try:
        loader = EnvironmentLoader()
        print("âœ“ EnvironmentLoader ç±»åˆå§‹åŒ–æˆåŠŸ")
        return loader
    except Exception as e:
        print(f"âœ— EnvironmentLoader ç±»åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def test_load_weather_data(loader):
    """æµ‹è¯•åŠ è½½å¤©æ°”æ•°æ®"""
    print("\n" + "=" * 60)
    print("TEST 1a: ä½¿ç”¨ EnvironmentLoader åŠ è½½å¤©æ°”æ•°æ®")
    print("=" * 60)
    
    if loader is None:
        print("âœ— Loader æœªåˆå§‹åŒ–")
        return None
    
    try:
        weather_file = "Testing_data/4_Testing_Weather_Data_2024_seasons_only.csv"
        df_weather = loader.load_weather_data(
            weather_file,
            handle_missing='drop',
            missing_threshold=0.5
        )
        print(f"\nâœ“ å¤©æ°”æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - å½¢çŠ¶: {df_weather.shape}")
        print(f"  - åˆ—å: {list(df_weather.columns[:5])}...")
        print(f"\næ•°æ®é¢„è§ˆ:")
        print(df_weather.head())
        return df_weather
    except Exception as e:
        print(f"âœ— å¤©æ°”æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_load_soil_data(loader):
    """æµ‹è¯•åŠ è½½åœŸå£¤æ•°æ®"""
    print("\n" + "=" * 60)
    print("TEST 1b: ä½¿ç”¨ EnvironmentLoader åŠ è½½åœŸå£¤æ•°æ®")
    print("=" * 60)
    
    if loader is None:
        print("âœ— Loader æœªåˆå§‹åŒ–")
        return None
    
    try:
        soil_file = "Testing_data/3_Testing_Soil_Data_2024.csv"
        df_soil = loader.load_soil_data(
            soil_file,
            handle_missing='drop',
            missing_threshold=0.5
        )
        print(f"\nâœ“ åœŸå£¤æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - å½¢çŠ¶: {df_soil.shape}")
        print(f"  - åˆ—å: {list(df_soil.columns[:5])}...")
        print(f"\næ•°æ®é¢„è§ˆ:")
        print(df_soil.head())
        return df_soil
    except Exception as e:
        print(f"âœ— åœŸå£¤æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_load_ec_data(loader):
    """æµ‹è¯•åŠ è½½ EC æ•°æ®"""
    print("\n" + "=" * 60)
    print("TEST 1c: ä½¿ç”¨ EnvironmentLoader åŠ è½½ EC æ•°æ®")
    print("=" * 60)
    
    if loader is None:
        print("âœ— Loader æœªåˆå§‹åŒ–")
        return None
    
    try:
        ec_file = "Testing_data/6_Testing_EC_Data_2024.csv"
        df_ec = loader.load_ec_data(
            ec_file,
            handle_missing='drop',
            missing_threshold=0.5
        )
        print(f"\nâœ“ EC æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - å½¢çŠ¶: {df_ec.shape}")
        print(f"  - åˆ—å: {list(df_ec.columns[:5])}...")
        print(f"\næ•°æ®é¢„è§ˆ:")
        print(df_ec.head())
        return df_ec
    except Exception as e:
        print(f"âœ— EC æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_load_all_environment_data(loader):
    """æµ‹è¯•åŠ è½½æ‰€æœ‰ç¯å¢ƒæ•°æ®"""
    print("\n" + "=" * 60)
    print("TEST 2: ä½¿ç”¨ EnvironmentLoader åŠ è½½æ‰€æœ‰ç¯å¢ƒæ•°æ®")
    print("=" * 60)
    
    if loader is None:
        print("âœ— Loader æœªåˆå§‹åŒ–")
        return None
    
    try:
        df_combined = loader.load_all_environment_data(
            weather_file='Testing_data/4_Testing_Weather_Data_2024_seasons_only.csv',
            soil_file='Testing_data/3_Testing_Soil_Data_2024.csv',
            ec_file='Testing_data/6_Testing_EC_Data_2024.csv',
            sample_col='Env',
            handle_missing='drop',
            missing_threshold=0.5
        )
        print(f"\nâœ“ æ‰€æœ‰ç¯å¢ƒæ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - å½¢çŠ¶: {df_combined.shape}")
        print(f"  - åˆ—å (å‰10åˆ—): {list(df_combined.columns[:10])}...")
        print(f"\næ•°æ®é¢„è§ˆ:")
        print(df_combined.head())
        return df_combined
    except Exception as e:
        print(f"âœ— æ‰€æœ‰ç¯å¢ƒæ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_data_loading():
    """æµ‹è¯•æ•°æ®æ–‡ä»¶çš„åŠ è½½"""
    print("=" * 60)
    print("TEST 3: ç›´æ¥ä½¿ç”¨ Pandas åŠ è½½æ•°æ®æ–‡ä»¶")
    print("=" * 60)
    
    # å®šä¹‰æ•°æ®æ–‡ä»¶è·¯å¾„
    soil_file = "Testing_data/3_Testing_Soil_Data_2024.csv"
    weather_file = "Testing_data/4_Testing_Weather_Data_2024_seasons_only.csv"
    ec_file = "Testing_data/6_Testing_EC_Data_2024.csv"
    
    try:
        # åŠ è½½åœŸå£¤æ•°æ®
        soil_df = pd.read_csv(soil_file)
        print(f"\nâœ“ åœŸå£¤æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - æ–‡ä»¶è¡Œæ•°: {len(soil_df)}")
        print(f"  - æ–‡ä»¶åˆ—æ•°: {len(soil_df.columns)}")
        print(f"  - ç¯å¢ƒIDæ•°é‡: {soil_df['Env'].nunique()}")
        print(f"  - ç¯å¢ƒID: {sorted(soil_df['Env'].unique())}")
        
        # åŠ è½½å¤©æ°”æ•°æ®
        weather_df = pd.read_csv(weather_file)
        print(f"\nâœ“ å¤©æ°”æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - æ–‡ä»¶è¡Œæ•°: {len(weather_df)}")
        print(f"  - æ–‡ä»¶åˆ—æ•°: {len(weather_df.columns)}")
        print(f"  - ç¯å¢ƒIDæ•°é‡: {weather_df['Env'].nunique()}")
        print(f"  - ç¯å¢ƒID: {sorted(weather_df['Env'].unique())}")
        
        # åŠ è½½ECæ•°æ®
        ec_df = pd.read_csv(ec_file)
        print(f"\nâœ“ ECæ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  - æ–‡ä»¶è¡Œæ•°: {len(ec_df)}")
        print(f"  - æ–‡ä»¶åˆ—æ•°: {len(ec_df.columns)}")
        print(f"  - ç¯å¢ƒIDæ•°é‡: {ec_df['Env'].nunique()}")
        print(f"  - ç¯å¢ƒID: {sorted(ec_df['Env'].unique())}")
        
        return soil_df, weather_df, ec_df
        
    except FileNotFoundError as e:
        print(f"âœ— æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return None, None, None


def test_soil_data_analysis(soil_df):
    """æµ‹è¯•åœŸå£¤æ•°æ®åˆ†æ"""
    print("\n" + "=" * 60)
    print("TEST 4: åœŸå£¤æ•°æ®åˆ†æ")
    print("=" * 60)
    
    if soil_df is None:
        print("âœ— åœŸå£¤æ•°æ®æœªåŠ è½½")
        return
    
    # åŸºæœ¬ç»Ÿè®¡
    numeric_cols = soil_df.select_dtypes(include=[np.number]).columns
    print(f"\næ•°å€¼åˆ—: {list(numeric_cols)}")
    
    print("\nåœŸå£¤æ•°æ®ç»Ÿè®¡:")
    print(soil_df[numeric_cols].describe())
    
    # æŒ‰ç¯å¢ƒåˆ†ç»„ç»Ÿè®¡
    print("\næŒ‰ç¯å¢ƒIDåˆ†ç»„çš„å¹³å‡å€¼:")
    grouped = soil_df.groupby('Env')[numeric_cols].mean()
    print(grouped)
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    print("\nç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing = soil_df.isnull().sum()
    print(missing[missing > 0])


def test_weather_data_analysis(weather_df):
    """æµ‹è¯•å¤©æ°”æ•°æ®åˆ†æ"""
    print("\n" + "=" * 60)
    print("TEST 5: å¤©æ°”æ•°æ®åˆ†æ")
    print("=" * 60)
    
    if weather_df is None:
        print("âœ— å¤©æ°”æ•°æ®æœªåŠ è½½")
        return
    
    # åŸºæœ¬ç»Ÿè®¡
    numeric_cols = weather_df.select_dtypes(include=[np.number]).columns
    print(f"\næ•°å€¼åˆ—: {list(numeric_cols)}")
    
    print("\nå¤©æ°”æ•°æ®ç»Ÿè®¡:")
    print(weather_df[numeric_cols].describe())
    
    # æŒ‰ç¯å¢ƒåˆ†ç»„ç»Ÿè®¡
    print("\næŒ‰ç¯å¢ƒIDåˆ†ç»„çš„å¹³å‡å€¼:")
    grouped = weather_df.groupby('Env')[numeric_cols].mean()
    print(grouped)
    
    # æ—¥æœŸèŒƒå›´
    print(f"\næ•°æ®æ—¥æœŸèŒƒå›´:")
    print(f"  - æœ€æ—©æ—¥æœŸ: {weather_df['Date'].min()}")
    print(f"  - æœ€æ™šæ—¥æœŸ: {weather_df['Date'].max()}")


def test_ec_data_analysis(ec_df):
    """æµ‹è¯• EC æ•°æ®åˆ†æ"""
    print("\n" + "=" * 60)
    print("TEST 6: EC æ•°æ®åˆ†æ")
    print("=" * 60)
    
    if ec_df is None:
        print("âœ— EC æ•°æ®æœªåŠ è½½")
        return
    
    print(f"\nç¯å¢ƒIDåŠå…¶æ•°æ®è¡Œæ•°:")
    env_counts = ec_df['Env'].value_counts().sort_index()
    print(env_counts)
    
    # æŸ¥çœ‹ä¸»è¦åˆ—
    print(f"\næ‰€æœ‰åˆ—å:")
    for i, col in enumerate(ec_df.columns, 1):
        print(f"  {i:2d}. {col}")
    
    # æ•°å€¼åˆ—ç»Ÿè®¡
    numeric_cols = ec_df.select_dtypes(include=[np.number]).columns
    print(f"\næ•°å€¼åˆ—ç»Ÿè®¡:")
    print(ec_df[numeric_cols].describe())


def test_data_consistency(soil_df, weather_df, ec_df):
    """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§"""
    print("\n" + "=" * 60)
    print("TEST 7: æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
    print("=" * 60)
    
    # è·å–æ¯ä¸ªæ•°æ®æºçš„ç¯å¢ƒID
    soil_envs = set(soil_df['Env'].unique()) if soil_df is not None else set()
    weather_envs = set(weather_df['Env'].unique()) if weather_df is not None else set()
    ec_envs = set(ec_df['Env'].unique()) if ec_df is not None else set()
    
    print(f"\nåœŸå£¤æ•°æ®ç¯å¢ƒ: {sorted(soil_envs)}")
    print(f"å¤©æ°”æ•°æ®ç¯å¢ƒ: {sorted(weather_envs)}")
    print(f"EC æ•°æ®ç¯å¢ƒ: {sorted(ec_envs)}")
    
    # æ£€æŸ¥äº¤é›†
    common_envs = soil_envs & weather_envs & ec_envs
    print(f"\nä¸‰ä¸ªæ•°æ®æºå…±æœ‰çš„ç¯å¢ƒ: {sorted(common_envs)}")
    print(f"å…±æœ‰ç¯å¢ƒæ•°é‡: {len(common_envs)}")
    
    # æ£€æŸ¥å·®å¼‚
    print(f"\nä»…åœ¨åœŸå£¤æ•°æ®ä¸­çš„ç¯å¢ƒ: {sorted(soil_envs - weather_envs - ec_envs)}")
    print(f"ä»…åœ¨å¤©æ°”æ•°æ®ä¸­çš„ç¯å¢ƒ: {sorted(weather_envs - soil_envs - ec_envs)}")
    print(f"ä»…åœ¨ EC æ•°æ®ä¸­çš„ç¯å¢ƒ: {sorted(ec_envs - soil_envs - weather_envs)}")


def test_merge_data(soil_df, weather_df, ec_df):
    """æµ‹è¯•æ•°æ®åˆå¹¶"""
    print("\n" + "=" * 60)
    print("TEST 8: æ•°æ®åˆå¹¶æµ‹è¯•")
    print("=" * 60)
    
    # æ‰¾ä¸€ä¸ªå…±æœ‰çš„ç¯å¢ƒ
    soil_envs = set(soil_df['Env'].unique()) if soil_df is not None else set()
    weather_envs = set(weather_df['Env'].unique()) if weather_df is not None else set()
    ec_envs = set(ec_df['Env'].unique()) if ec_df is not None else set()
    common_envs = soil_envs & weather_envs & ec_envs
    
    if not common_envs:
        print("âœ— æ²¡æœ‰å…±æœ‰çš„ç¯å¢ƒ")
        return
    
    test_env = sorted(common_envs)[0]
    
    try:
        soil_subset = soil_df[soil_df['Env'] == test_env].copy()
        weather_subset = weather_df[weather_df['Env'] == test_env].copy()
        ec_subset = ec_df[ec_df['Env'] == test_env].copy()
        
        print(f"\nç¯å¢ƒ {test_env} çš„æ•°æ®è¡Œæ•°:")
        print(f"  - åœŸå£¤æ•°æ®: {len(soil_subset)} è¡Œ")
        print(f"  - å¤©æ°”æ•°æ®: {len(weather_subset)} è¡Œ")
        print(f"  - EC æ•°æ®: {len(ec_subset)} è¡Œ")
        
        if len(soil_subset) > 0:
            print(f"\nåœŸå£¤æ•°æ®æ ·æœ¬ (å‰3è¡Œ):")
            print(soil_subset.head(3))
        
        if len(weather_subset) > 0:
            print(f"\nå¤©æ°”æ•°æ®æ ·æœ¬ (å‰3è¡Œ):")
            print(weather_subset.head(3))
        
        if len(ec_subset) > 0:
            print(f"\nEC æ•°æ®æ ·æœ¬ (å‰3è¡Œ):")
            print(ec_subset.head(3))
            
    except Exception as e:
        print(f"âœ— æ•°æ®åˆå¹¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def convert_weather_to_3d(df_weather: pd.DataFrame, 
                          sample_col: str = 'Env', 
                          date_col: str = 'Date') -> tuple:
    """
    å°†é•¿æ ¼å¼å¤©æ°” DataFrame è½¬æ¢ä¸º 3D NumPy æ•°ç»„
    
    Parameters:
        df_weather: é•¿æ ¼å¼å¤©æ°”æ•°æ®
        sample_col: æ ·æœ¬IDåˆ—å
        date_col: æ—¥æœŸåˆ—å
    
    Returns:
        tuple: (weather_3d, sample_ids, feature_names)
               weather_3d å½¢çŠ¶: (n_samples, n_timesteps, n_features)
    """
    # è·å–ç‰¹å¾åˆ—ï¼ˆæ’é™¤æ ·æœ¬IDå’Œæ—¥æœŸï¼‰
    feature_cols = [col for col in df_weather.columns 
                   if col not in [sample_col, date_col]]
    
    # æŒ‰æ ·æœ¬åˆ†ç»„å¹¶æ’åº
    grouped_data = []
    sample_ids = []
    
    for sample_id, group in df_weather.groupby(sample_col):
        group_sorted = group.sort_values(date_col)
        features = group_sorted[feature_cols].values
        grouped_data.append(features)
        sample_ids.append(sample_id)
    
    # æ£€æŸ¥æ—¶é—´æ­¥æ•°
    timesteps = [len(t) for t in grouped_data]
    if len(set(timesteps)) > 1:
        print(f"âš ï¸ æ—¶é—´æ­¥æ•°ä¸ä¸€è‡´: {set(timesteps)}")
        # å¡«å……åˆ°æœ€å¤§æ—¶é—´æ­¥æ•°
        max_t = max(timesteps)
        padded = []
        for data in grouped_data:
            if len(data) < max_t:
                pad = np.repeat(data[-1:], max_t - len(data), axis=0)
                data = np.vstack([data, pad])
            padded.append(data)
        grouped_data = padded
    
    # è½¬æ¢ä¸º 3D æ•°ç»„
    weather_3d = np.array(grouped_data, dtype=np.float32)
    
    print(f"âœ“ è½¬æ¢ä¸º 3D æ•°ç»„:")
    print(f"  - å½¢çŠ¶: {weather_3d.shape}")
    print(f"  - ç»´åº¦: (æ ·æœ¬={len(sample_ids)}, æ—¶é—´æ­¥={weather_3d.shape[1]}, ç‰¹å¾={len(feature_cols)})")
    
    return weather_3d, sample_ids, feature_cols


def load_all_data_and_merge(loader, output_dir="output"):
    """
    âœ… ã€æ–°å¢ã€‘åŠ è½½æ‰€æœ‰æ•°æ®å¹¶åˆå¹¶
    
    Parameters:
        loader: EnvironmentLoader å®ä¾‹
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        tuple: (df_weather, df_soil, df_ec, df_combined)
    """
    
    print("\n" + "=" * 70)
    print("åŠ è½½ä¸‰ä¸ªæ•°æ®æ–‡ä»¶ï¼ˆå¤©æ°”æ–‡ä»¶ä¸åšèšåˆï¼‰")
    print("=" * 70)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    try:
        # âœ… ã€å…³é”®ã€‘åŠ è½½å¤©æ°”æ•°æ®ï¼Œreshape_to_temporal=True ä¿ç•™åŸå§‹æ—¶é—´åºåˆ—
        print("\nğŸ“ ç¬¬1æ­¥ï¼šåŠ è½½å¤©æ°”æ•°æ®ï¼ˆä¿ç•™æ—¶é—´åºåˆ—ï¼Œä¸åšèšåˆï¼‰")
        print("-" * 70)
        df_weather = loader.load_weather_data(
            filepath="Testing_data/4_Testing_Weather_Data_2024_seasons_only.csv",
            reshape_to_temporal=True,  # âœ… ä¿ç•™æ—¶é—´åºåˆ—
            sample_col="Env",
            date_col="Date",
            handle_missing='drop',
            missing_threshold=0.5
        )
        print(f"\nâœ“ å¤©æ°”æ•°æ®åŠ è½½å®Œæˆ")
        print(f"  - å½¢çŠ¶: {df_weather.shape}")
        
        # âœ… ã€æ–°å¢ã€‘è½¬æ¢ä¸º 3D æ•°ç»„
        print("\n  è½¬æ¢ä¸º 3D æ•°ç»„...")
        weather_3d, sample_ids, feature_names = convert_weather_to_3d(
            df_weather, 
            sample_col='Env', 
            date_col='Date'
        )
        print(f"  - 3D å½¢çŠ¶: {weather_3d.shape}")
        print(f"  - æ ·æœ¬æ•°: {len(sample_ids)}")
        print(f"  - æ—¶é—´æ­¥: {weather_3d.shape[1]}")
        print(f"  - ç‰¹å¾æ•°: {weather_3d.shape[2]}")
        
        # âœ… åŠ è½½åœŸå£¤æ•°æ®
        print("\n\nğŸ“ ç¬¬2æ­¥ï¼šåŠ è½½åœŸå£¤æ•°æ®")
        print("-" * 70)
        df_soil = loader.load_soil_data(
            filepath="Testing_data/3_Testing_Soil_Data_2024.csv",
            handle_missing='drop',
            missing_threshold=0.5,
            sample_col='Env'
        )
        print(f"\nâœ“ åœŸå£¤æ•°æ®åŠ è½½å®Œæˆ")
        print(f"  - å½¢çŠ¶: {df_soil.shape}")
        print(f"  - åˆ—æ•°: {len(df_soil.columns)}")
        print(f"  - ç¯å¢ƒæ•°: {df_soil['Env'].nunique()}")
        print(f"  - æ ·æœ¬ID: {sorted(df_soil['Env'].unique())}")
        print(f"\nåœŸå£¤æ•°æ®é¢„è§ˆï¼ˆå‰3è¡Œï¼‰:")
        print(df_soil.head(3))
        
        # âœ… åŠ è½½ EC æ•°æ®
        print("\n\nğŸ“ ç¬¬3æ­¥ï¼šåŠ è½½ EC æ•°æ®")
        print("-" * 70)
        df_ec = loader.load_ec_data(
            filepath="Testing_data/6_Testing_EC_Data_2024.csv",
            handle_missing='drop',
            missing_threshold=0.5,
            sample_col='Env'
        )
        print(f"\nâœ“ EC æ•°æ®åŠ è½½å®Œæˆ")
        print(f"  - å½¢çŠ¶: {df_ec.shape}")
        print(f"  - åˆ—æ•°: {len(df_ec.columns)}")
        print(f"  - ç¯å¢ƒæ•°: {df_ec['Env'].nunique()}")
        print(f"  - æ ·æœ¬ID: {sorted(df_ec['Env'].unique())}")
        print(f"\nEC æ•°æ®é¢„è§ˆï¼ˆå‰3è¡Œï¼‰:")
        print(df_ec.head(3))
        
        # âœ… æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
        print("\n\nğŸ“ ç¬¬4æ­¥ï¼šæ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
        print("-" * 70)
        weather_envs = set(df_weather['Env'].unique())
        soil_envs = set(df_soil['Env'].unique())
        ec_envs = set(df_ec['Env'].unique())
        
        print(f"\nå¤©æ°”æ•°æ®ç¯å¢ƒ: {sorted(weather_envs)}")
        print(f"åœŸå£¤æ•°æ®ç¯å¢ƒ: {sorted(soil_envs)}")
        print(f"EC æ•°æ®ç¯å¢ƒ: {sorted(ec_envs)}")
        
        common_envs = weather_envs & soil_envs & ec_envs
        print(f"\nâœ“ ä¸‰ä¸ªæ•°æ®æºå…±æœ‰ç¯å¢ƒ: {sorted(common_envs)}")
        print(f"  å…±æœ‰ç¯å¢ƒæ•°é‡: {len(common_envs)}")
        
        # âœ… åˆå¹¶æ•°æ®
        print("\n\nğŸ“ ç¬¬5æ­¥ï¼šåˆå¹¶ä¸‰ä¸ªæ•°æ®æº")
        print("-" * 70)
        
        # å…ˆåˆå¹¶åœŸå£¤å’Œ EC æ•°æ®ï¼ˆé™æ€æ•°æ®ï¼Œ1è¡Œ/æ ·æœ¬ï¼‰
        print("\n  5.1 åˆå¹¶åœŸå£¤å’Œ EC æ•°æ®...")
        df_merged = df_soil.merge(df_ec, on='Env', how='inner')
        print(f"      âœ“ åˆå¹¶åå½¢çŠ¶: {df_merged.shape}")
        
        # å†åˆå¹¶å¤©æ°”æ•°æ®ï¼ˆæ—¶é—´åºåˆ—æ•°æ®ï¼Œå¤šè¡Œ/æ ·æœ¬ï¼‰
        print("\n  5.2 åˆå¹¶å¤©æ°”æ•°æ®...")
        df_combined = df_weather.merge(df_merged, on='Env', how='inner')
        print(f"      âœ“ åˆå¹¶åå½¢çŠ¶: {df_combined.shape}")
        
        print(f"\nâœ“ æ•°æ®åˆå¹¶å®Œæˆ")
        print(f"  - æ€»è¡Œæ•°: {len(df_combined)}")
        print(f"  - æ€»åˆ—æ•°: {len(df_combined.columns)}")
        print(f"  - ç¯å¢ƒæ•°: {df_combined['Env'].nunique()}")
        
        print(f"\nåˆå¹¶åæ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰:")
        print(df_combined.head(5))
        
        # âœ… ä¿å­˜ä¸º CSV æ–‡ä»¶
        print("\n\nğŸ“ ç¬¬6æ­¥ï¼šä¿å­˜ä¸º CSV æ–‡ä»¶")
        print("-" * 70)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_path / f"combined_environment_data_{timestamp}.csv"
        
        df_combined.to_csv(output_file, index=False)
        
        print(f"\nâœ“ æ•°æ®å·²ä¿å­˜")
        print(f"  - æ–‡ä»¶è·¯å¾„: {output_file}")
        print(f"  - æ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024:.2f} KB")
        print(f"  - è¡Œæ•°: {len(df_combined)}")
        print(f"  - åˆ—æ•°: {len(df_combined.columns)}")
        
        # âœ… æ˜¾ç¤ºæ•°æ®æ‘˜è¦
        print("\n\nğŸ“‹ æ•°æ®æ‘˜è¦")
        print("=" * 70)
        print(f"\nå¤©æ°”æ•°æ®:")
        print(f"  - è¡Œæ•°: {len(df_weather)}")
        print(f"  - åˆ—æ•°: {len(df_weather.columns)}")
        print(f"  - æ—¶é—´èŒƒå›´: {df_weather['Date'].min()} åˆ° {df_weather['Date'].max()}")
        print(f"  - ç¯å¢ƒæ•°: {df_weather['Env'].nunique()}")
        
        print(f"\nåœŸå£¤æ•°æ®:")
        print(f"  - è¡Œæ•°: {len(df_soil)}")
        print(f"  - åˆ—æ•°: {len(df_soil.columns)}")
        print(f"  - ç¯å¢ƒæ•°: {df_soil['Env'].nunique()}")
        
        print(f"\nEC æ•°æ®:")
        print(f"  - è¡Œæ•°: {len(df_ec)}")
        print(f"  - åˆ—æ•°: {len(df_ec.columns)}")
        print(f"  - ç¯å¢ƒæ•°: {df_ec['Env'].nunique()}")
        
        print(f"\nåˆå¹¶åæ•°æ®:")
        print(f"  - è¡Œæ•°: {len(df_combined)}")
        print(f"  - åˆ—æ•°: {len(df_combined.columns)}")
        print(f"  - ç¯å¢ƒæ•°: {df_combined['Env'].nunique()}")
        print(f"  - è¾“å‡ºæ–‡ä»¶: {output_file.name}")
        
        return df_weather, df_soil, df_ec, df_combined
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None, None


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n")
    print("â•”" + "=" * 68 + "â•—")
    print("â•‘" + " " * 68 + "â•‘")
    print("â•‘" + "  åŠ è½½ä¸‰ä¸ªæ•°æ®æ–‡ä»¶å¹¶è¾“å‡ºä¸º CSV".center(68) + "â•‘")
    print("â•‘" + " " * 68 + "â•‘")
    print("â•š" + "=" * 68 + "â•")
    
    # åˆå§‹åŒ– EnvironmentLoader
    print("\nåˆå§‹åŒ– EnvironmentLoader...")
    try:
        loader = EnvironmentLoader()
        print("âœ“ EnvironmentLoader åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âœ— EnvironmentLoader åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # âœ… ã€å…³é”®ã€‘åŠ è½½æ•°æ®å¹¶åˆå¹¶
    df_weather, df_soil, df_ec, df_combined = load_all_data_and_merge(
        loader, 
        output_dir="output"
    )
    
    if df_combined is not None:
        print("\n\n" + "=" * 70)
        print("âœ“ æˆåŠŸï¼æ•°æ®å·²ä¿å­˜åˆ° output ç›®å½•")
        print("=" * 70)
        
        # æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶åˆ—è¡¨
        output_path = Path("output")
        csv_files = list(output_path.glob("*.csv"))
        if csv_files:
            print(f"\nç”Ÿæˆçš„ CSV æ–‡ä»¶:")
            for i, file in enumerate(csv_files, 1):
                print(f"  {i}. {file.name} ({file.stat().st_size / 1024:.2f} KB)")
    else:
        print("\nâŒ æ•°æ®åŠ è½½å¤±è´¥")


if __name__ == "__main__":
    main()